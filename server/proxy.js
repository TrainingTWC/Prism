/**
 * Simple proxy server for GitHub Models API
 * Handles CORS issues by proxying requests from browser to GitHub Models
 */

import express from 'express';
import cors from 'cors';
import fetch from 'node-fetch';
import dotenv from 'dotenv';

// Load environment variables
dotenv.config();

const app = express();
// Allow overriding port via environment variable to avoid conflicts with dev server
const PORT = process.env.AI_PROXY_PORT ? parseInt(process.env.AI_PROXY_PORT, 10) : (process.env.PORT ? parseInt(process.env.PORT, 10) : 3003);

// Configure CORS with restrictions
// âš ï¸ TODO: Update with your actual production domain
const allowedOrigins = process.env.NODE_ENV === 'production'
  ? [
      'https://yourdomain.com',
      'https://www.yourdomain.com'
      // Add your production domains here
    ]
  : [
      'http://localhost:3000',
      'http://localhost:3001',
      'http://localhost:5173', // Vite default
      'http://localhost:5174',
      'http://192.168.120.219:3001' // Your internal network
    ];

app.use(cors({
  origin: function (origin, callback) {
    // Allow requests with no origin (mobile apps, curl, etc.)
    if (!origin) return callback(null, true);
    
    if (allowedOrigins.includes(origin)) {
      callback(null, true);
    } else {
      console.warn('âš ï¸  CORS blocked request from:', origin);
      callback(new Error('Not allowed by CORS'));
    }
  },
  credentials: true,
  methods: ['GET', 'POST'],
  allowedHeaders: ['Content-Type', 'Authorization'],
  maxAge: 86400 // 24 hours
}));

app.use(express.json({ limit: '10mb' }));

// Health check endpoint
app.get('/health', (req, res) => {
  res.json({ status: 'ok', message: 'Proxy server is running' });
});

// Proxy endpoint for GitHub Models API
app.post('/api/ai/analyze', async (req, res) => {
  const token = process.env.VITE_GITHUB_TOKEN;
  
  if (!token) {
    return res.status(500).json({ 
      error: 'GitHub token not configured',
      message: 'Please set VITE_GITHUB_TOKEN in .env file'
    });
  }

  try {
    console.log('ğŸš€ Proxying request to GitHub Models API...');
    console.log('Request body size:', JSON.stringify(req.body).length, 'bytes');
    
    // Validate request body
    if (!req.body || !req.body.model || !req.body.messages) {
      console.error('âŒ Invalid request body');
      return res.status(400).json({
        error: 'Invalid request',
        message: 'Request must include model and messages'
      });
    }
    
  // Use the GitHub Models inference endpoint per repository docs
  const response = await fetch('https://models.github.ai/inference/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
        'User-Agent': 'TWC-Prism-Dashboard'
      },
      body: JSON.stringify(req.body)
    });

    // Get response as text first to handle non-JSON errors
    const text = await response.text();

    // Log upstream response status and a snippet for diagnostics
    console.log('ğŸ” Upstream status:', response.status, response.statusText);
    console.log('ğŸ” Upstream response snippet:', String(text).slice(0, 1024));

    if (!response.ok) {
      console.error(`âŒ GitHub Models API error: ${response.status} ${response.statusText}`);
      // Try to parse as JSON, fallback to include raw text
      try {
        const errorData = JSON.parse(text);
        return res.status(response.status).json(errorData);
      } catch (parseErr) {
        console.error('âŒ Failed to parse upstream error as JSON:', parseErr.message);
        return res.status(response.status).json({ 
          error: response.statusText,
          message: String(text).slice(0, 4096),
          status: response.status
        });
      }
    }

    // Attempt to parse successful response as JSON; if parsing fails, return diagnostics
    try {
      const data = JSON.parse(text);
      console.log('âœ… GitHub Models API success');
      return res.json(data);
    } catch (parseErr) {
      console.error('âŒ Upstream returned non-JSON for success response:', parseErr.message);
      // Return a clear 502 with the raw upstream text for debugging (trim to reasonable size)
      return res.status(502).json({
        error: 'Upstream returned non-JSON',
        message: String(text).slice(0, 8192),
        status: response.status
      });
    }
    
  } catch (error) {
    console.error('âŒ Proxy error:', error);
    res.status(500).json({ 
      error: 'Proxy error',
      message: error.message 
    });
  }
});

app.listen(PORT, () => {
  console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                           â•‘
â•‘  ğŸ¤– AI Insights Proxy Server                              â•‘
â•‘                                                           â•‘
â•‘  Status: âœ… Running on http://localhost:${PORT}            â•‘
â•‘                                                           â•‘
â•‘  This proxy forwards requests from your React app         â•‘
â•‘  to GitHub Models API, solving CORS issues.               â•‘
â•‘                                                           â•‘
â•‘  Endpoints:                                               â•‘
â•‘    GET  /health          - Health check                   â•‘
â•‘    POST /api/ai/analyze  - AI analysis proxy              â•‘
â•‘                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  `);
});
